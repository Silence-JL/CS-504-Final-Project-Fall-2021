{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 174,
     "status": "ok",
     "timestamp": 1638337647395,
     "user": {
      "displayName": "Silence Ma",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "01344304277965432029"
     },
     "user_tz": 480
    },
    "id": "zeD4P8QM8dJO",
    "outputId": "2dea18a8-fa7f-45ee-a9f5-581711709e75"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "# mount google drive on your runtime using and authorization code.\n",
    "# more details here: https://colab.research.google.com/notebooks/io.ipynb\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2622,
     "status": "ok",
     "timestamp": 1638337650213,
     "user": {
      "displayName": "Silence Ma",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "01344304277965432029"
     },
     "user_tz": 480
    },
    "id": "1uCE3qzElzGx",
    "outputId": "ad9563e6-9847-4a88-c109-2aa9b8584f5f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: adversarial-robustness-toolbox in /usr/local/lib/python3.7/dist-packages (1.8.1)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from adversarial-robustness-toolbox) (1.4.1)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from adversarial-robustness-toolbox) (57.4.0)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from adversarial-robustness-toolbox) (1.15.0)\n",
      "Requirement already satisfied: scikit-learn<1.1.0,>=0.22.2 in /usr/local/lib/python3.7/dist-packages (from adversarial-robustness-toolbox) (1.0.1)\n",
      "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.7/dist-packages (from adversarial-robustness-toolbox) (1.19.5)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from adversarial-robustness-toolbox) (4.62.3)\n",
      "Requirement already satisfied: numba>=0.53.1 in /usr/local/lib/python3.7/dist-packages (from adversarial-robustness-toolbox) (0.54.1)\n",
      "Requirement already satisfied: llvmlite<0.38,>=0.37.0rc1 in /usr/local/lib/python3.7/dist-packages (from numba>=0.53.1->adversarial-robustness-toolbox) (0.37.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn<1.1.0,>=0.22.2->adversarial-robustness-toolbox) (3.0.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn<1.1.0,>=0.22.2->adversarial-robustness-toolbox) (1.1.0)\n"
     ]
    }
   ],
   "source": [
    "# install adversarial robustness toolbox for attacking (NEED TO RESTART RUNTIME AT FIRST TIME)\n",
    "!pip install adversarial-robustness-toolbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6104,
     "status": "ok",
     "timestamp": 1638337656295,
     "user": {
      "displayName": "Silence Ma",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "01344304277965432029"
     },
     "user_tz": 480
    },
    "id": "dOC-SEl9_Tqg",
    "outputId": "7228681f-02c8-40cd-cf1d-c82fc941bb3e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPUs Available:  [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "Device mapping:\n",
      "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# import library\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Model\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pickle\n",
    "import os\n",
    "import cv2\n",
    "from google.colab.patches import cv2_imshow\n",
    "from imutils import paths\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from art.estimators.classification import KerasClassifier\n",
    "from art.attacks.evasion import FastGradientMethod,ProjectedGradientDescent\n",
    "\n",
    "# check GPU is available\n",
    "print(\"GPUs Available: \", tf.config.list_physical_devices('GPU'))\n",
    "\n",
    "# set random seed of tensorflow\n",
    "random.seed(1)\n",
    "np.random.seed(1)\n",
    "tf.compat.v1.set_random_seed(1)\n",
    "tf.random.set_seed(1)\n",
    "config = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1,log_device_placement =True)\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.compat.v1.Session(graph = tf.compat.v1.get_default_graph(), config = config)\n",
    "tf.compat.v1.keras.backend.set_session(sess)\n",
    "tf.compat.v1.disable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ehwA9Thy_T-r"
   },
   "outputs": [],
   "source": [
    "# Path to the directory containing the project files (CHANGE THIS PATH TO THE DIRECTORY ON YOUR COMPUTER OR GOOGLE DRIVE)\n",
    "PROJECT_ROOT_DIR = 'drive/My Drive/CS504(AML)/HW1/BUSI/'\n",
    "\n",
    "# Path to the directory containing the dataset (DOWNLOAD THE BUSI_DATASET DIRECTORY FROM FOLLOWING LINK)\n",
    "# DOWNLOAD BUSI dataset here: https://scholar.cu.edu.eg/?q=afahmy/pages/dataset\n",
    "DATA_DIR = 'Dataset_BUSI_with_GT/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O3ZttfbFdAA1"
   },
   "source": [
    "# Load the BUSI images and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "code",
    "id": "LTxT38-8_k7v"
   },
   "outputs": [],
   "source": [
    "# Funciton for loading the dataset\n",
    "# reference: https://www.pyimagesearch.com/2018/09/10/keras-tutorial-how-to-get-started-with-keras-deep-learning-and-python/\n",
    "def load_image():\n",
    "  # initialize the data and labels for each class\n",
    "  data = []\n",
    "  labels = []\n",
    "\n",
    "  data_aside = []\n",
    "  labels_aside = []\n",
    "\n",
    "  benign_data = []\n",
    "  benign_labels = []\n",
    "\n",
    "  malignant_data = []\n",
    "  malignant_labels = []\n",
    "\n",
    "  normal_data = []\n",
    "  normal_labels = []\n",
    "\n",
    "  # load benign image\n",
    "  for i in range(1,438):\n",
    "    image = cv2.imread(PROJECT_ROOT_DIR + DATA_DIR + 'benign/' + 'benign (' + str(i) + ').png')\n",
    "    # resize image to 224 * 224 * 3\n",
    "    image = cv2.resize(image, (224, 224))\n",
    "    benign_data.append(image)\n",
    "    # extract the class label from the image folder\n",
    "    benign_labels.append('benign')\n",
    "  # random Select 120 images and set them aside as Adversarial Attack images. These include 60 benign images, 30 malignant images, and 30 normal images\n",
    "  # select 60 benign images\n",
    "  random.seed(1)\n",
    "  random_sample = random.sample(range(len(benign_data)),60)\n",
    "  for i in range(0,437):\n",
    "    if i in random_sample:\n",
    "      data_aside.append(benign_data[i])\n",
    "      labels_aside.append(benign_labels[i])\n",
    "    else:\n",
    "      data.append(benign_data[i])\n",
    "      labels.append(benign_labels[i])\n",
    "\n",
    "  # load malignant image\n",
    "  for i in range(1,211):\n",
    "    image = cv2.imread(PROJECT_ROOT_DIR + DATA_DIR + 'malignant/' + 'malignant (' + str(i) + ').png')\n",
    "    # resize image to 224 * 224 * 3\n",
    "    image = cv2.resize(image, (224, 224))\n",
    "    malignant_data.append(image)\n",
    "    # extract the class label from the image folder\n",
    "    malignant_labels.append('malignant')\n",
    "  # select 30 malignant images\n",
    "  random.seed(1)\n",
    "  random_sample = random.sample(range(len(malignant_data)),30)\n",
    "  for i in range(0,210):\n",
    "    if i in random_sample:\n",
    "      data_aside.append(malignant_data[i])\n",
    "      labels_aside.append(malignant_labels[i])\n",
    "    else:\n",
    "      data.append(malignant_data[i])\n",
    "      labels.append(malignant_labels[i])\n",
    "  \n",
    "  # load normal image\n",
    "  for i in range(1,134):\n",
    "    image = cv2.imread(PROJECT_ROOT_DIR + DATA_DIR + 'normal/' + 'normal (' + str(i) + ').png')\n",
    "    # resize image to 224 * 224 * 3\n",
    "    image = cv2.resize(image, (224, 224))\n",
    "    normal_data.append(image)\n",
    "    # extract the class label from the image folder\n",
    "    normal_labels.append('normal')\n",
    "  # select 30 normal images\n",
    "  random.seed(1)\n",
    "  random_sample = random.sample(range(len(normal_data)),30)\n",
    "  for i in range(0,133):\n",
    "    if i in random_sample:\n",
    "      data_aside.append(normal_data[i])\n",
    "      labels_aside.append(normal_labels[i])\n",
    "    else:\n",
    "      data.append(normal_data[i])\n",
    "      labels.append(normal_labels[i])  \n",
    "\n",
    "  return data, labels, data_aside, labels_aside\n",
    "# Function for image preprocessing \n",
    "def preprocess(data,labels,data_aside, labels_aside):\n",
    "  # Save training and test image to numpy, Scale image features to be in [0, 1]\n",
    "  data = np.array(data, dtype = np.float32) / 255.0\n",
    "  # Save labels to numpy encode label to integer catergory 0 = 'benign', 1 = 'malignant', 2 = 'normal'\n",
    "  labels = np.array(labels)\n",
    "  new_label_encoder = preprocessing.LabelEncoder()\n",
    "  new_label_encoder.fit(labels)\n",
    "  targets = new_label_encoder.transform(labels)\n",
    "  # Save aside image to numpy, Scale image features to be in [0, 1]\n",
    "  data_aside = np.array(data_aside, dtype = np.float32) / 255.0\n",
    "  # Save labels to numpy encode label to integer catergory 0 = 'benign', 1 = 'malignant', 2 = 'normal' \n",
    "  labels_aside = np.array(labels_aside)\n",
    "  new_labels_aside_encoder = preprocessing.LabelEncoder()\n",
    "  new_labels_aside_encoder.fit(labels_aside)\n",
    "  targets2 = new_label_encoder.transform(labels_aside)\n",
    "  return data, targets, data_aside, targets2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sfx8YFwEUggO"
   },
   "outputs": [],
   "source": [
    "# Load the images and labels\n",
    "data, labels, data_aside, labels_aside = load_image()\n",
    "data, labels, data_aside, labels_aside = preprocess(data,labels,data_aside, labels_aside)\n",
    "\n",
    "# split data into 80% train and 20% test, shuffle the data with\n",
    "(imgs_train, imgs_test, labels_train, labels_test) = train_test_split(data, labels, test_size = 0.2, random_state=42, shuffle = True)\n",
    "# split data into 60% train data and 20% validation data\n",
    "(imgs_train, imgs_val, labels_train, labels_val) = train_test_split(imgs_train, labels_train, test_size = 0.2, random_state=42, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 29,
     "status": "ok",
     "timestamp": 1638337857624,
     "user": {
      "displayName": "Silence Ma",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "01344304277965432029"
     },
     "user_tz": 480
    },
    "id": "YFX8ENErVXih",
    "outputId": "e031ec0a-4d32-4d56-d35d-d48d2a2bac19"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images train shape: (422, 224, 224, 3) - Labels train shape: (422,)\n",
      "Images validation shape: (106, 224, 224, 3) - Labels validation shape: (106,)\n",
      "Images test shape: (132, 224, 224, 3) - Labels test shape: (132,)\n",
      "Aside images shape: (120, 224, 224, 3) - Aside Labels shape: (120,)\n",
      "\n",
      "Max pixel value 1.0\n",
      "Min pixel value 0.0\n",
      "Average pixel value 0.32330388\n",
      "Data type float32\n"
     ]
    }
   ],
   "source": [
    "# Display the shapes of train, validation, and test datasets\n",
    "print('Images train shape: {} - Labels train shape: {}'.format(imgs_train.shape, labels_train.shape))\n",
    "print('Images validation shape: {} - Labels validation shape: {}'.format(imgs_val.shape, labels_val.shape))\n",
    "print('Images test shape: {} - Labels test shape: {}'.format(imgs_test.shape, labels_test.shape))\n",
    "print('Aside images shape: {} - Aside Labels shape: {}'.format(data_aside.shape, labels_aside.shape))\n",
    "# Display the range of images (to make sure they are in the [0, 1] range)\n",
    "print('\\nMax pixel value', np.max(imgs_train))\n",
    "print('Min pixel value', np.min(imgs_train))\n",
    "print('Average pixel value', np.mean(imgs_train))\n",
    "print('Data type', imgs_train[0].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FaCAEmH8X3pP"
   },
   "outputs": [],
   "source": [
    "# Set constants (BUSI)\n",
    "NUM_LABELS = 3                             # Number of labels\n",
    "BATCH_SIZE = 4                             # Size of batch\n",
    "HEIGHT = 224                                 # Height of input image\n",
    "WIDTH = 224                                  # Width of input image\n",
    "N_CHANNEL = 3                               # Number of channels\n",
    "OUTPUT_DIM = 3                             # Number of output dimension\n",
    "\n",
    "# Set training hyperparameters\n",
    "NUM_EPOCH = 100                             # Number of epoch to train\n",
    "LR = 0.01                                 # Learning rate\n",
    "\n",
    "INPUT_SHAPE = (HEIGHT, WIDTH, N_CHANNEL)  # Input shape of model\n",
    "IMG_SHAPE = (HEIGHT, WIDTH, N_CHANNEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1638337857626,
     "user": {
      "displayName": "Silence Ma",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "01344304277965432029"
     },
     "user_tz": 480
    },
    "id": "_8AzkPCGX-0g",
    "outputId": "cfd45fb0-6ea4-42a0-b52f-30a53b05e353"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels train shape: (422, 3)\n"
     ]
    }
   ],
   "source": [
    "# Convert the labels to one-hot encoding (to input to the models)\n",
    "labels_train = keras.utils.to_categorical(labels_train, NUM_LABELS)\n",
    "labels_test = keras.utils.to_categorical(labels_test, NUM_LABELS)\n",
    "labels_val = keras.utils.to_categorical(labels_val, NUM_LABELS)\n",
    "labels_aside = keras.utils.to_categorical(labels_aside, NUM_LABELS)\n",
    "print('Labels train shape: {}'.format(labels_train.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uu0BOVlgZdzy"
   },
   "source": [
    "# Load ResNet50 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14693,
     "status": "ok",
     "timestamp": 1638337872307,
     "user": {
      "displayName": "Silence Ma",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "01344304277965432029"
     },
     "user_tz": 480
    },
    "id": "WvS8-ymJbLfu",
    "outputId": "f35c6659-ca24-4e74-a60a-87410a0d6e4d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/layers/normalization/batch_normalization.py:532: _colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "# load ResNet50 and build model\n",
    "model = keras.models.load_model(PROJECT_ROOT_DIR + 'BUSI_dataset_resnet50.h5')\n",
    "model.build((224,224,3))\n",
    "# SGD optimizer\n",
    "optimizer = keras.optimizers.SGD(learning_rate=LR)\n",
    "# compile the keras model\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer = optimizer, metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9458,
     "status": "ok",
     "timestamp": 1638337881754,
     "user": {
      "displayName": "Silence Ma",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "01344304277965432029"
     },
     "user_tz": 480
    },
    "id": "j5rV6kb16-zW",
    "outputId": "76a76e6a-9f4c-4714-a2e4-22a155b034d9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/keras/engine/training_v1.py:2057: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates = self.state_updates\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "orignial resnet50 aside test loss, test acc: [0.901405859241883, 0.85]\n"
     ]
    }
   ],
   "source": [
    "# evaluate the keras model with aside images\n",
    "results = model.evaluate(data_aside, labels_aside)\n",
    "print(\"orignial resnet50 aside test loss, test acc:\", results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P0lpyVOQZu-j"
   },
   "source": [
    "# Create and apply Fast Gradient Sign Method Attack with ART onResNet 50 (using 120 aside images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gCSuyJeHl89l"
   },
   "outputs": [],
   "source": [
    "# Create a ART Keras classifier for the TensorFlow Keras model.\n",
    "classifier = KerasClassifier(model = model,clip_values=(0, 1), use_logits=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15381,
     "status": "ok",
     "timestamp": 1638337901796,
     "user": {
      "displayName": "Silence Ma",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "01344304277965432029"
     },
     "user_tz": 480
    },
    "id": "YABmqew9mmD5",
    "outputId": "cfadc041-3448-4f77-a26b-e27b609aeaf2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/keras/engine/training_v1.py:2079: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on adversarial test data: 26.67%\n",
      "Average perturbation: 0.10\n"
     ]
    }
   ],
   "source": [
    "# Create a ART FGSM attack.\n",
    "attack_fgsm = FastGradientMethod(estimator = classifier, norm = np.inf, eps = 0.1, targeted = False)\n",
    "# Generate adversarial test data.\n",
    "x_test_adv = attack_fgsm.generate(data_aside)\n",
    "# Evaluate accuracy on adversarial test data and calculate average perturbation.\n",
    "loss_test, accuracy_test = model.evaluate(x_test_adv, labels_aside)\n",
    "perturbation = np.mean(np.abs((x_test_adv - data_aside)))\n",
    "print('Accuracy on adversarial test data: {:4.2f}%'.format(accuracy_test * 100))\n",
    "print('Average perturbation: {:4.2f}'.format(perturbation))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "muq_N-PAZjfR"
   },
   "source": [
    "# Implement adversarial aside examples to ML models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9i91DMcqYROU"
   },
   "outputs": [],
   "source": [
    "# copy all images into a new variable\n",
    "x_train = imgs_train.copy()\n",
    "# flatten image features in train, test, aside and adversarial aside images\n",
    "x_train = x_train.reshape(x_train.shape[0],224*224*3)\n",
    "\n",
    "x_test = imgs_test.copy()\n",
    "x_test = x_test.reshape(x_test.shape[0],224*224*3)\n",
    "\n",
    "x_aside = data_aside.copy()\n",
    "x_aside = x_aside.reshape(x_aside.shape[0],224*224*3)\n",
    "\n",
    "x_fgsm = x_test_adv.copy()\n",
    "x_fgsm = x_fgsm.reshape(x_fgsm.shape[0],224*224*3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7190,
     "status": "ok",
     "timestamp": 1638337962727,
     "user": {
      "displayName": "Silence Ma",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "01344304277965432029"
     },
     "user_tz": 480
    },
    "id": "63SYjMWvlZ1u",
    "outputId": "d1e1daee-5ecc-455c-de17-046918c66c18"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy:  0.5606060606060606\n",
      "aside accuracy:  0.5416666666666666\n",
      "FGSM aside accuracy:  0.525\n"
     ]
    }
   ],
   "source": [
    "# K nearest neighbors\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "neigh = KNeighborsClassifier(n_neighbors = 3)\n",
    "neigh.fit(x_train, np.argmax(labels_train,axis = 1))\n",
    "\n",
    "print('test accuracy: ',neigh.score(x_test,np.argmax(labels_test,axis = 1)))\n",
    "print('aside accuracy: ',neigh.score(x_aside,np.argmax(labels_aside,axis = 1)))\n",
    "print('FGSM aside accuracy: ',neigh.score(x_fgsm, np.argmax(labels_aside,axis = 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 31900,
     "status": "ok",
     "timestamp": 1638337994613,
     "user": {
      "displayName": "Silence Ma",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "01344304277965432029"
     },
     "user_tz": 480
    },
    "id": "I4_6x4GJlCjn",
    "outputId": "6bd692d2-300f-4da5-a690-1ad48f4c7369"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy:  0.48484848484848486\n",
      "aside accuracy:  0.525\n",
      "FGSM aside accuracy:  0.4166666666666667\n"
     ]
    }
   ],
   "source": [
    "# Decision tree\n",
    "from sklearn import tree\n",
    "\n",
    "tr = tree.DecisionTreeClassifier()\n",
    "tr.fit(x_train, np.argmax(labels_train,axis = 1))\n",
    "print('test accuracy: ',tr.score(x_test,np.argmax(labels_test,axis = 1)))\n",
    "print('aside accuracy: ',tr.score(x_aside,np.argmax(labels_aside,axis = 1)))\n",
    "print('FGSM aside accuracy: ',tr.score(x_fgsm, np.argmax(labels_aside,axis = 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 305347,
     "status": "ok",
     "timestamp": 1638338299923,
     "user": {
      "displayName": "Silence Ma",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "01344304277965432029"
     },
     "user_tz": 480
    },
    "id": "Ud2qahE2udvU",
    "outputId": "f85f1ac3-f64a-417f-a42d-122bc1fcaac4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy:  0.6439393939393939\n",
      "aside accuracy:  0.6166666666666667\n",
      "FGSM aside accuracy:  0.625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/scipy/optimize/linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(penalty='l2', dual=False, tol=0.0001, C=1.0, fit_intercept=True, intercept_scaling=1, \n",
    "                           class_weight='balanced', random_state=0, solver='newton-cg', max_iter=100, \n",
    "                           multi_class='auto', verbose=0, warm_start=False, n_jobs=None)\n",
    "lr.fit(x_train, np.argmax(labels_train,axis = 1))\n",
    "print('test accuracy: ',lr.score(x_test,np.argmax(labels_test,axis = 1)))\n",
    "print('aside accuracy: ',lr.score(x_aside,np.argmax(labels_aside,axis = 1)))\n",
    "print('FGSM aside accuracy: ',lr.score(x_fgsm, np.argmax(labels_aside,axis = 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 89315,
     "status": "ok",
     "timestamp": 1638338389206,
     "user": {
      "displayName": "Silence Ma",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "01344304277965432029"
     },
     "user_tz": 480
    },
    "id": "cVGEDlvNu8Ri",
    "outputId": "1469fe43-34df-4e75-e45f-c634e5b0a546"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy:  0.6742424242424242\n",
      "aside accuracy:  0.6083333333333333\n",
      "FGSM aside accuracy:  0.5833333333333334\n"
     ]
    }
   ],
   "source": [
    "# Support vector machine\n",
    "from sklearn import svm\n",
    "\n",
    "svm_1 = svm.SVC()\n",
    "svm_1.fit(x_train, np.argmax(labels_train,axis = 1))\n",
    "print('test accuracy: ',svm_1.score(x_test,np.argmax(labels_test,axis = 1)))\n",
    "print('aside accuracy: ',svm_1.score(x_aside,np.argmax(labels_aside,axis = 1)))\n",
    "print('FGSM aside accuracy: ',svm_1.score(x_fgsm, np.argmax(labels_aside,axis = 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1279,
     "status": "ok",
     "timestamp": 1638338390445,
     "user": {
      "displayName": "Silence Ma",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "01344304277965432029"
     },
     "user_tz": 480
    },
    "id": "L3evximEvdhz",
    "outputId": "087ba232-a403-4351-cd97-f4c7beafc244"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy:  0.5757575757575758\n",
      "aside accuracy:  0.4666666666666667\n",
      "FGSM aside accuracy:  0.3333333333333333\n"
     ]
    }
   ],
   "source": [
    "# Navie Bayers\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "nb = BernoulliNB()\n",
    "nb.fit(x_train, np.argmax(labels_train,axis = 1))\n",
    "print('test accuracy: ',nb.score(x_test,np.argmax(labels_test,axis = 1)))\n",
    "print('aside accuracy: ',nb.score(x_aside,np.argmax(labels_aside,axis = 1)))\n",
    "print('FGSM aside accuracy: ',nb.score(x_fgsm, np.argmax(labels_aside,axis = 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 462593,
     "status": "ok",
     "timestamp": 1638338853030,
     "user": {
      "displayName": "Silence Ma",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "01344304277965432029"
     },
     "user_tz": 480
    },
    "id": "7oXTG9zmwVrz",
    "outputId": "6d25cfdb-b7f0-4cee-e2b5-7bcfbf9f8c1a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy:  0.6893939393939394\n",
      "aside accuracy:  0.6\n",
      "FGSM aside accuracy:  0.5833333333333334\n"
     ]
    }
   ],
   "source": [
    "# Bagging classifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "bag = BaggingClassifier(base_estimator=SVC(), n_estimators=10, random_state=0)\n",
    "bag.fit(x_train, np.argmax(labels_train,axis = 1))\n",
    "print('test accuracy: ',bag.score(x_test,np.argmax(labels_test,axis = 1)))\n",
    "print('aside accuracy: ',bag.score(x_aside,np.argmax(labels_aside,axis = 1)))\n",
    "print('FGSM aside accuracy: ',bag.score(x_fgsm, np.argmax(labels_aside,axis = 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1972,
     "status": "ok",
     "timestamp": 1638338854965,
     "user": {
      "displayName": "Silence Ma",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "01344304277965432029"
     },
     "user_tz": 480
    },
    "id": "_-UdhoBhwv8_",
    "outputId": "466111d2-e5bd-4e69-d21e-8750f8267c20"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy:  0.6515151515151515\n",
      "aside accuracy:  0.575\n",
      "FGSM aside accuracy:  0.5333333333333333\n"
     ]
    }
   ],
   "source": [
    "# Random forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "rf.fit(x_train, np.argmax(labels_train,axis = 1))\n",
    "print('test accuracy: ',rf.score(x_test,np.argmax(labels_test,axis = 1)))\n",
    "print('aside accuracy: ',rf.score(x_aside,np.argmax(labels_aside,axis = 1)))\n",
    "print('FGSM aside accuracy: ',rf.score(x_fgsm, np.argmax(labels_aside,axis = 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3124,
     "status": "ok",
     "timestamp": 1638338858076,
     "user": {
      "displayName": "Silence Ma",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "01344304277965432029"
     },
     "user_tz": 480
    },
    "id": "GYRBEv13xAMs",
    "outputId": "aefe8675-8453-4f6e-b8bc-a9fc780de609"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy:  0.7348484848484849\n",
      "aside accuracy:  0.6666666666666666\n",
      "FGSM aside accuracy:  0.6083333333333333\n"
     ]
    }
   ],
   "source": [
    "# Extra trees\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "ec =  ExtraTreesClassifier(n_estimators=100, random_state=0)\n",
    "ec.fit(x_train, np.argmax(labels_train,axis = 1))\n",
    "print('test accuracy: ',ec.score(x_test,np.argmax(labels_test,axis = 1)))\n",
    "print('aside accuracy: ',ec.score(x_aside,np.argmax(labels_aside,axis = 1)))\n",
    "print('FGSM aside accuracy: ',ec.score(x_fgsm, np.argmax(labels_aside,axis = 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1337759,
     "status": "ok",
     "timestamp": 1638340195808,
     "user": {
      "displayName": "Silence Ma",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "01344304277965432029"
     },
     "user_tz": 480
    },
    "id": "7R3SnIGoxJrH",
    "outputId": "af5f6d5e-439b-4443-b1c3-585de2335541"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy:  0.6287878787878788\n",
      "aside accuracy:  0.6166666666666667\n",
      "FGSM aside accuracy:  0.4583333333333333\n"
     ]
    }
   ],
   "source": [
    "# Gradient boosting\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "gb = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=1, random_state=0)\n",
    "gb.fit(x_train, np.argmax(labels_train,axis = 1))\n",
    "print('test accuracy: ',gb.score(x_test,np.argmax(labels_test,axis = 1)))\n",
    "print('aside accuracy: ',gb.score(x_aside,np.argmax(labels_aside,axis = 1)))\n",
    "print('FGSM aside accuracy: ',gb.score(x_fgsm, np.argmax(labels_aside,axis = 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 30020,
     "status": "ok",
     "timestamp": 1638340225823,
     "user": {
      "displayName": "Silence Ma",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "01344304277965432029"
     },
     "user_tz": 480
    },
    "id": "hCKyFQShFmSL",
    "outputId": "8f348dc4-8e6f-4b37-be4c-96e525c7727a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/keras/engine/training_v1.py:2057: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates = self.state_updates\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FGSM MobileNet aside test loss, test acc: [7.166088395400826, 0.5]\n"
     ]
    }
   ],
   "source": [
    "# load MobileNet and build model\n",
    "SAVE_ROOT_DIR = 'drive/My Drive/CS504(AML)/Course Project/'\n",
    "model_MobileNet = keras.models.load_model(SAVE_ROOT_DIR + 'BUSI_dataset_MobileNet.h5')\n",
    "model_MobileNet.build((224,224,3))\n",
    "# Adam optimizer\n",
    "optimizer = keras.optimizers.Adam(learning_rate=0.0001)\n",
    "# compile the keras model\n",
    "model_MobileNet.compile(loss = 'categorical_crossentropy', optimizer = optimizer, metrics = ['accuracy'])\n",
    "# evaluate the keras model with aside images\n",
    "results = model_MobileNet.evaluate(x_test_adv, labels_aside)\n",
    "print(\"FGSM MobileNet aside test loss, test acc:\", results)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMGlr/1m50ce8KfFM1zBP+Y",
   "collapsed_sections": [],
   "name": "BUSI_resnet50_FGSM.ipynb",
   "provenance": [
    {
     "file_id": "1TLdt1Kf9meFF7zXHhCnuBSTaie9khwHI",
     "timestamp": 1638251177821
    },
    {
     "file_id": "1Hecpe9FBPCSVVJ3HE6prAXWy5-Xv4DmW",
     "timestamp": 1630906214757
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
