{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 510,
     "status": "ok",
     "timestamp": 1638340384309,
     "user": {
      "displayName": "Silence Ma",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "01344304277965432029"
     },
     "user_tz": 480
    },
    "id": "zeD4P8QM8dJO",
    "outputId": "5da2a7d0-5d36-4e14-803a-1b906d755c0e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "# mount google drive on your runtime using and authorization code.\n",
    "# more details here: https://colab.research.google.com/notebooks/io.ipynb\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3233,
     "status": "ok",
     "timestamp": 1638340387929,
     "user": {
      "displayName": "Silence Ma",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "01344304277965432029"
     },
     "user_tz": 480
    },
    "id": "1uCE3qzElzGx",
    "outputId": "59aaa7d7-e6a8-4db3-da21-a23f4016d5c7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: adversarial-robustness-toolbox in /usr/local/lib/python3.7/dist-packages (1.8.1)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from adversarial-robustness-toolbox) (4.62.3)\n",
      "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.7/dist-packages (from adversarial-robustness-toolbox) (1.19.5)\n",
      "Requirement already satisfied: scikit-learn<1.1.0,>=0.22.2 in /usr/local/lib/python3.7/dist-packages (from adversarial-robustness-toolbox) (1.0.1)\n",
      "Requirement already satisfied: numba>=0.53.1 in /usr/local/lib/python3.7/dist-packages (from adversarial-robustness-toolbox) (0.54.1)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from adversarial-robustness-toolbox) (1.4.1)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from adversarial-robustness-toolbox) (1.15.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from adversarial-robustness-toolbox) (57.4.0)\n",
      "Requirement already satisfied: llvmlite<0.38,>=0.37.0rc1 in /usr/local/lib/python3.7/dist-packages (from numba>=0.53.1->adversarial-robustness-toolbox) (0.37.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn<1.1.0,>=0.22.2->adversarial-robustness-toolbox) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn<1.1.0,>=0.22.2->adversarial-robustness-toolbox) (3.0.0)\n"
     ]
    }
   ],
   "source": [
    "# install adversarial robustness toolbox for attacking (NEED TO RESTART RUNTIME AT FIRST TIME)\n",
    "!pip install adversarial-robustness-toolbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4093,
     "status": "ok",
     "timestamp": 1638340392011,
     "user": {
      "displayName": "Silence Ma",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "01344304277965432029"
     },
     "user_tz": 480
    },
    "id": "dOC-SEl9_Tqg",
    "outputId": "798f4ef6-9d7b-4702-d4c9-95544147a25d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPUs Available:  [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "Device mapping:\n",
      "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# import library\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Model\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pickle\n",
    "import os\n",
    "import cv2\n",
    "from google.colab.patches import cv2_imshow\n",
    "from imutils import paths\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from art.estimators.classification import KerasClassifier\n",
    "from art.attacks.evasion import FastGradientMethod,ProjectedGradientDescent\n",
    "\n",
    "# check GPU is available\n",
    "print(\"GPUs Available: \", tf.config.list_physical_devices('GPU'))\n",
    "\n",
    "# set random seed of tensorflow\n",
    "random.seed(1)\n",
    "np.random.seed(1)\n",
    "tf.compat.v1.set_random_seed(1)\n",
    "tf.random.set_seed(1)\n",
    "config = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1,log_device_placement =True)\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.compat.v1.Session(graph = tf.compat.v1.get_default_graph(), config = config)\n",
    "tf.compat.v1.keras.backend.set_session(sess)\n",
    "tf.compat.v1.disable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ehwA9Thy_T-r"
   },
   "outputs": [],
   "source": [
    "# Path to the directory containing the project files (CHANGE THIS PATH TO THE DIRECTORY ON YOUR COMPUTER OR GOOGLE DRIVE)\n",
    "PROJECT_ROOT_DIR = 'drive/My Drive/CS504(AML)/HW1/BUSI/'\n",
    "\n",
    "# Path to the directory containing the dataset (DOWNLOAD THE BUSI_DATASET DIRECTORY FROM FOLLOWING LINK)\n",
    "# DOWNLOAD BUSI dataset here: https://scholar.cu.edu.eg/?q=afahmy/pages/dataset\n",
    "DATA_DIR = 'Dataset_BUSI_with_GT/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O3ZttfbFdAA1"
   },
   "source": [
    "# Load the BUSI images and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "code",
    "id": "LTxT38-8_k7v"
   },
   "outputs": [],
   "source": [
    "# Funciton for loading the dataset\n",
    "# reference: https://www.pyimagesearch.com/2018/09/10/keras-tutorial-how-to-get-started-with-keras-deep-learning-and-python/\n",
    "def load_image():\n",
    "  # initialize the data and labels for each class\n",
    "  data = []\n",
    "  labels = []\n",
    "\n",
    "  data_aside = []\n",
    "  labels_aside = []\n",
    "\n",
    "  benign_data = []\n",
    "  benign_labels = []\n",
    "\n",
    "  malignant_data = []\n",
    "  malignant_labels = []\n",
    "\n",
    "  normal_data = []\n",
    "  normal_labels = []\n",
    "\n",
    "  # load benign image\n",
    "  for i in range(1,438):\n",
    "    image = cv2.imread(PROJECT_ROOT_DIR + DATA_DIR + 'benign/' + 'benign (' + str(i) + ').png')\n",
    "    # resize image to 224 * 224 * 3\n",
    "    image = cv2.resize(image, (224, 224))\n",
    "    benign_data.append(image)\n",
    "    # extract the class label from the image folder\n",
    "    benign_labels.append('benign')\n",
    "  # random Select 120 images and set them aside as Adversarial Attack images. These include 60 benign images, 30 malignant images, and 30 normal images\n",
    "  # select 60 benign images\n",
    "  random.seed(1)\n",
    "  random_sample = random.sample(range(len(benign_data)),60)\n",
    "  for i in range(0,437):\n",
    "    if i in random_sample:\n",
    "      data_aside.append(benign_data[i])\n",
    "      labels_aside.append(benign_labels[i])\n",
    "    else:\n",
    "      data.append(benign_data[i])\n",
    "      labels.append(benign_labels[i])\n",
    "\n",
    "  # load malignant image\n",
    "  for i in range(1,211):\n",
    "    image = cv2.imread(PROJECT_ROOT_DIR + DATA_DIR + 'malignant/' + 'malignant (' + str(i) + ').png')\n",
    "    # resize image to 224 * 224 * 3\n",
    "    image = cv2.resize(image, (224, 224))\n",
    "    malignant_data.append(image)\n",
    "    # extract the class label from the image folder\n",
    "    malignant_labels.append('malignant')\n",
    "  # select 30 malignant images\n",
    "  random.seed(1)\n",
    "  random_sample = random.sample(range(len(malignant_data)),30)\n",
    "  for i in range(0,210):\n",
    "    if i in random_sample:\n",
    "      data_aside.append(malignant_data[i])\n",
    "      labels_aside.append(malignant_labels[i])\n",
    "    else:\n",
    "      data.append(malignant_data[i])\n",
    "      labels.append(malignant_labels[i])\n",
    "  \n",
    "  # load normal image\n",
    "  for i in range(1,134):\n",
    "    image = cv2.imread(PROJECT_ROOT_DIR + DATA_DIR + 'normal/' + 'normal (' + str(i) + ').png')\n",
    "    # resize image to 224 * 224 * 3\n",
    "    image = cv2.resize(image, (224, 224))\n",
    "    normal_data.append(image)\n",
    "    # extract the class label from the image folder\n",
    "    normal_labels.append('normal')\n",
    "  # select 30 normal images\n",
    "  random.seed(1)\n",
    "  random_sample = random.sample(range(len(normal_data)),30)\n",
    "  for i in range(0,133):\n",
    "    if i in random_sample:\n",
    "      data_aside.append(normal_data[i])\n",
    "      labels_aside.append(normal_labels[i])\n",
    "    else:\n",
    "      data.append(normal_data[i])\n",
    "      labels.append(normal_labels[i])  \n",
    "\n",
    "  return data, labels, data_aside, labels_aside\n",
    "# Function for image preprocessing \n",
    "def preprocess(data,labels,data_aside, labels_aside):\n",
    "  # Save training and test image to numpy, Scale image features to be in [0, 1]\n",
    "  data = np.array(data, dtype = np.float32) / 255.0\n",
    "  # Save labels to numpy encode label to integer catergory 0 = 'benign', 1 = 'malignant', 2 = 'normal'\n",
    "  labels = np.array(labels)\n",
    "  new_label_encoder = preprocessing.LabelEncoder()\n",
    "  new_label_encoder.fit(labels)\n",
    "  targets = new_label_encoder.transform(labels)\n",
    "  # Save aside image to numpy, Scale image features to be in [0, 1]\n",
    "  data_aside = np.array(data_aside, dtype = np.float32) / 255.0\n",
    "  # Save labels to numpy encode label to integer catergory 0 = 'benign', 1 = 'malignant', 2 = 'normal' \n",
    "  labels_aside = np.array(labels_aside)\n",
    "  new_labels_aside_encoder = preprocessing.LabelEncoder()\n",
    "  new_labels_aside_encoder.fit(labels_aside)\n",
    "  targets2 = new_label_encoder.transform(labels_aside)\n",
    "  return data, targets, data_aside, targets2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sfx8YFwEUggO"
   },
   "outputs": [],
   "source": [
    "# Load the images and labels\n",
    "data, labels, data_aside, labels_aside = load_image()\n",
    "data, labels, data_aside, labels_aside = preprocess(data,labels,data_aside, labels_aside)\n",
    "\n",
    "# split data into 80% train and 20% test, shuffle the data with\n",
    "(imgs_train, imgs_test, labels_train, labels_test) = train_test_split(data, labels, test_size = 0.2, random_state=42, shuffle = True)\n",
    "# split data into 60% train data and 20% validation data\n",
    "(imgs_train, imgs_val, labels_train, labels_val) = train_test_split(imgs_train, labels_train, test_size = 0.2, random_state=42, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 63,
     "status": "ok",
     "timestamp": 1638340784055,
     "user": {
      "displayName": "Silence Ma",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "01344304277965432029"
     },
     "user_tz": 480
    },
    "id": "YFX8ENErVXih",
    "outputId": "a1aac574-ec20-4203-ddb0-722f84def965"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images train shape: (422, 224, 224, 3) - Labels train shape: (422,)\n",
      "Images validation shape: (106, 224, 224, 3) - Labels validation shape: (106,)\n",
      "Images test shape: (132, 224, 224, 3) - Labels test shape: (132,)\n",
      "Aside images shape: (120, 224, 224, 3) - Aside Labels shape: (120,)\n",
      "\n",
      "Max pixel value 1.0\n",
      "Min pixel value 0.0\n",
      "Average pixel value 0.32330388\n",
      "Data type float32\n"
     ]
    }
   ],
   "source": [
    "# Display the shapes of train, validation, and test datasets\n",
    "print('Images train shape: {} - Labels train shape: {}'.format(imgs_train.shape, labels_train.shape))\n",
    "print('Images validation shape: {} - Labels validation shape: {}'.format(imgs_val.shape, labels_val.shape))\n",
    "print('Images test shape: {} - Labels test shape: {}'.format(imgs_test.shape, labels_test.shape))\n",
    "print('Aside images shape: {} - Aside Labels shape: {}'.format(data_aside.shape, labels_aside.shape))\n",
    "# Display the range of images (to make sure they are in the [0, 1] range)\n",
    "print('\\nMax pixel value', np.max(imgs_train))\n",
    "print('Min pixel value', np.min(imgs_train))\n",
    "print('Average pixel value', np.mean(imgs_train))\n",
    "print('Data type', imgs_train[0].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FaCAEmH8X3pP"
   },
   "outputs": [],
   "source": [
    "# Set constants (BUSI)\n",
    "NUM_LABELS = 3                             # Number of labels\n",
    "BATCH_SIZE = 4                             # Size of batch\n",
    "HEIGHT = 224                                 # Height of input image\n",
    "WIDTH = 224                                  # Width of input image\n",
    "N_CHANNEL = 3                               # Number of channels\n",
    "OUTPUT_DIM = 3                             # Number of output dimension\n",
    "\n",
    "# Set training hyperparameters\n",
    "NUM_EPOCH = 100                             # Number of epoch to train\n",
    "LR = 0.01                                 # Learning rate\n",
    "\n",
    "INPUT_SHAPE = (HEIGHT, WIDTH, N_CHANNEL)  # Input shape of model\n",
    "IMG_SHAPE = (HEIGHT, WIDTH, N_CHANNEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 57,
     "status": "ok",
     "timestamp": 1638340784059,
     "user": {
      "displayName": "Silence Ma",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "01344304277965432029"
     },
     "user_tz": 480
    },
    "id": "_8AzkPCGX-0g",
    "outputId": "cbe0dabf-0689-4972-e8eb-d9cd64e86110"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels train shape: (422, 3)\n"
     ]
    }
   ],
   "source": [
    "# Convert the labels to one-hot encoding (to input to the models)\n",
    "labels_train = keras.utils.to_categorical(labels_train, NUM_LABELS)\n",
    "labels_test = keras.utils.to_categorical(labels_test, NUM_LABELS)\n",
    "labels_val = keras.utils.to_categorical(labels_val, NUM_LABELS)\n",
    "labels_aside = keras.utils.to_categorical(labels_aside, NUM_LABELS)\n",
    "print('Labels train shape: {}'.format(labels_train.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uu0BOVlgZdzy"
   },
   "source": [
    "# Load ResNet50 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 23471,
     "status": "ok",
     "timestamp": 1638340807482,
     "user": {
      "displayName": "Silence Ma",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "01344304277965432029"
     },
     "user_tz": 480
    },
    "id": "WvS8-ymJbLfu",
    "outputId": "cafc246d-8c41-4f68-8b0d-61841f1447e4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/layers/normalization/batch_normalization.py:532: _colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "# load ResNet50 and build model\n",
    "model = keras.models.load_model(PROJECT_ROOT_DIR + 'BUSI_dataset_resnet50.h5')\n",
    "model.build((224,224,3))\n",
    "# SGD optimizer\n",
    "optimizer = keras.optimizers.SGD(learning_rate=LR)\n",
    "# compile the keras model\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer = optimizer, metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10246,
     "status": "ok",
     "timestamp": 1638340817687,
     "user": {
      "displayName": "Silence Ma",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "01344304277965432029"
     },
     "user_tz": 480
    },
    "id": "j5rV6kb16-zW",
    "outputId": "0d9864a5-7644-4a91-c763-602ee4858fd7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/keras/engine/training_v1.py:2057: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates = self.state_updates\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "orignial resnet50 aside test loss, test acc: [0.9014058622221152, 0.85]\n"
     ]
    }
   ],
   "source": [
    "# evaluate the keras model with aside images\n",
    "results = model.evaluate(data_aside, labels_aside)\n",
    "print(\"orignial resnet50 aside test loss, test acc:\", results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P0lpyVOQZu-j"
   },
   "source": [
    "# Create and apply Projected Gradient Descent Attack with ART onResNet 50 (using 120 aside images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gCSuyJeHl89l"
   },
   "outputs": [],
   "source": [
    "# Create a ART Keras classifier for the TensorFlow Keras model.\n",
    "classifier = KerasClassifier(model = model,clip_values=(0, 1), use_logits=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1363634,
     "status": "ok",
     "timestamp": 1638342188059,
     "user": {
      "displayName": "Silence Ma",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "01344304277965432029"
     },
     "user_tz": 480
    },
    "id": "YABmqew9mmD5",
    "outputId": "b622b29d-3a51-4f15-f62f-6bb238844b71"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/keras/engine/training_v1.py:2079: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on adversarial test data: 9.17%\n",
      "Average perturbation: 0.06\n"
     ]
    }
   ],
   "source": [
    "# Create a ART PGD attack.\n",
    "attack_pgd = ProjectedGradientDescent(estimator = classifier, norm = np.inf, eps = 0.1, eps_step = 0.01, max_iter = 200, targeted = False, verbose = False)\n",
    "# Generate adversarial test data.\n",
    "x_test_adv = attack_pgd.generate(data_aside)\n",
    "# Evaluate accuracy on adversarial test data and calculate average perturbation.\n",
    "loss_test, accuracy_test = model.evaluate(x_test_adv, labels_aside)\n",
    "perturbation = np.mean(np.abs((x_test_adv - data_aside)))\n",
    "print('Accuracy on adversarial test data: {:4.2f}%'.format(accuracy_test * 100))\n",
    "print('Average perturbation: {:4.2f}'.format(perturbation))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "muq_N-PAZjfR"
   },
   "source": [
    "# Implement adversarial aside examples to ML models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9i91DMcqYROU"
   },
   "outputs": [],
   "source": [
    "# copy all images into a new variable\n",
    "x_train = imgs_train.copy()\n",
    "# flatten image features in train, test, aside and adversarial aside images\n",
    "x_train = x_train.reshape(x_train.shape[0],224*224*3)\n",
    "\n",
    "x_test = imgs_test.copy()\n",
    "x_test = x_test.reshape(x_test.shape[0],224*224*3)\n",
    "\n",
    "x_aside = data_aside.copy()\n",
    "x_aside = x_aside.reshape(x_aside.shape[0],224*224*3)\n",
    "\n",
    "x_pgd = x_test_adv.copy()\n",
    "x_pgd = x_pgd.reshape(x_pgd.shape[0],224*224*3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6548,
     "status": "ok",
     "timestamp": 1638342194597,
     "user": {
      "displayName": "Silence Ma",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "01344304277965432029"
     },
     "user_tz": 480
    },
    "id": "63SYjMWvlZ1u",
    "outputId": "d2adcbe5-46cf-4b56-f330-ddc59b2f2c7d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy:  0.5606060606060606\n",
      "aside accuracy:  0.5416666666666666\n",
      "PGD aside accuracy:  0.5333333333333333\n"
     ]
    }
   ],
   "source": [
    "# K nearest neighbors\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "neigh = KNeighborsClassifier(n_neighbors = 3)\n",
    "neigh.fit(x_train, np.argmax(labels_train,axis = 1))\n",
    "\n",
    "print('test accuracy: ',neigh.score(x_test,np.argmax(labels_test,axis = 1)))\n",
    "print('aside accuracy: ',neigh.score(x_aside,np.argmax(labels_aside,axis = 1)))\n",
    "print('PGD aside accuracy: ',neigh.score(x_pgd, np.argmax(labels_aside,axis = 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 30098,
     "status": "ok",
     "timestamp": 1638342224660,
     "user": {
      "displayName": "Silence Ma",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "01344304277965432029"
     },
     "user_tz": 480
    },
    "id": "I4_6x4GJlCjn",
    "outputId": "59261337-6be9-4622-eeaf-32775434b777"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy:  0.48484848484848486\n",
      "aside accuracy:  0.525\n",
      "PGD aside accuracy:  0.48333333333333334\n"
     ]
    }
   ],
   "source": [
    "# Decision tree\n",
    "from sklearn import tree\n",
    "\n",
    "tr = tree.DecisionTreeClassifier()\n",
    "tr.fit(x_train, np.argmax(labels_train,axis = 1))\n",
    "print('test accuracy: ',tr.score(x_test,np.argmax(labels_test,axis = 1)))\n",
    "print('aside accuracy: ',tr.score(x_aside,np.argmax(labels_aside,axis = 1)))\n",
    "print('PGD aside accuracy: ',tr.score(x_pgd, np.argmax(labels_aside,axis = 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 220225,
     "status": "ok",
     "timestamp": 1638342444874,
     "user": {
      "displayName": "Silence Ma",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "01344304277965432029"
     },
     "user_tz": 480
    },
    "id": "Ud2qahE2udvU",
    "outputId": "5705865f-abbb-42f0-8210-a2a6a005e1b9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy:  0.6439393939393939\n",
      "aside accuracy:  0.6166666666666667\n",
      "PGD aside accuracy:  0.625\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(penalty='l2', dual=False, tol=0.0001, C=1.0, fit_intercept=True, intercept_scaling=1, \n",
    "                           class_weight='balanced', random_state=0, solver='newton-cg', max_iter=100, \n",
    "                           multi_class='auto', verbose=0, warm_start=False, n_jobs=None)\n",
    "lr.fit(x_train, np.argmax(labels_train,axis = 1))\n",
    "print('test accuracy: ',lr.score(x_test,np.argmax(labels_test,axis = 1)))\n",
    "print('aside accuracy: ',lr.score(x_aside,np.argmax(labels_aside,axis = 1)))\n",
    "print('PGD aside accuracy: ',lr.score(x_pgd, np.argmax(labels_aside,axis = 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 78719,
     "status": "ok",
     "timestamp": 1638342523552,
     "user": {
      "displayName": "Silence Ma",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "01344304277965432029"
     },
     "user_tz": 480
    },
    "id": "cVGEDlvNu8Ri",
    "outputId": "5ae70849-80ec-45aa-ab8e-6b2e730f1e57"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy:  0.6742424242424242\n",
      "aside accuracy:  0.6083333333333333\n",
      "PGD aside accuracy:  0.5833333333333334\n"
     ]
    }
   ],
   "source": [
    "# Support vector machine\n",
    "from sklearn import svm\n",
    "\n",
    "svm_1 = svm.SVC()\n",
    "svm_1.fit(x_train, np.argmax(labels_train,axis = 1))\n",
    "print('test accuracy: ',svm_1.score(x_test,np.argmax(labels_test,axis = 1)))\n",
    "print('aside accuracy: ',svm_1.score(x_aside,np.argmax(labels_aside,axis = 1)))\n",
    "print('PGD aside accuracy: ',svm_1.score(x_pgd, np.argmax(labels_aside,axis = 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 895,
     "status": "ok",
     "timestamp": 1638342524415,
     "user": {
      "displayName": "Silence Ma",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "01344304277965432029"
     },
     "user_tz": 480
    },
    "id": "L3evximEvdhz",
    "outputId": "1bb04ee4-2a02-45b8-f8fe-49068c8a4a20"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy:  0.5757575757575758\n",
      "aside accuracy:  0.4666666666666667\n",
      "PGD aside accuracy:  0.39166666666666666\n"
     ]
    }
   ],
   "source": [
    "# Navie Bayers\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "nb = BernoulliNB()\n",
    "nb.fit(x_train, np.argmax(labels_train,axis = 1))\n",
    "print('test accuracy: ',nb.score(x_test,np.argmax(labels_test,axis = 1)))\n",
    "print('aside accuracy: ',nb.score(x_aside,np.argmax(labels_aside,axis = 1)))\n",
    "print('PGD aside accuracy: ',nb.score(x_pgd, np.argmax(labels_aside,axis = 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 501738,
     "status": "ok",
     "timestamp": 1638343026145,
     "user": {
      "displayName": "Silence Ma",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "01344304277965432029"
     },
     "user_tz": 480
    },
    "id": "7oXTG9zmwVrz",
    "outputId": "53c12dfa-9acb-4f1b-d98c-847fead7649e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy:  0.6893939393939394\n",
      "aside accuracy:  0.6\n",
      "PGD aside accuracy:  0.5916666666666667\n"
     ]
    }
   ],
   "source": [
    "# Bagging classifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "bag = BaggingClassifier(base_estimator=SVC(), n_estimators=10, random_state=0)\n",
    "bag.fit(x_train, np.argmax(labels_train,axis = 1))\n",
    "print('test accuracy: ',bag.score(x_test,np.argmax(labels_test,axis = 1)))\n",
    "print('aside accuracy: ',bag.score(x_aside,np.argmax(labels_aside,axis = 1)))\n",
    "print('PGD aside accuracy: ',bag.score(x_pgd, np.argmax(labels_aside,axis = 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1892,
     "status": "ok",
     "timestamp": 1638343028024,
     "user": {
      "displayName": "Silence Ma",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "01344304277965432029"
     },
     "user_tz": 480
    },
    "id": "_-UdhoBhwv8_",
    "outputId": "145d2962-8cff-4c0d-aac8-b6e2e5335295"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy:  0.6515151515151515\n",
      "aside accuracy:  0.575\n",
      "PGD aside accuracy:  0.5833333333333334\n"
     ]
    }
   ],
   "source": [
    "# Random forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "rf.fit(x_train, np.argmax(labels_train,axis = 1))\n",
    "print('test accuracy: ',rf.score(x_test,np.argmax(labels_test,axis = 1)))\n",
    "print('aside accuracy: ',rf.score(x_aside,np.argmax(labels_aside,axis = 1)))\n",
    "print('PGD aside accuracy: ',rf.score(x_pgd, np.argmax(labels_aside,axis = 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3203,
     "status": "ok",
     "timestamp": 1638343031219,
     "user": {
      "displayName": "Silence Ma",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "01344304277965432029"
     },
     "user_tz": 480
    },
    "id": "GYRBEv13xAMs",
    "outputId": "948c5824-72b0-468e-ec13-c972199c9e27"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy:  0.7348484848484849\n",
      "aside accuracy:  0.6666666666666666\n",
      "PGD aside accuracy:  0.6\n"
     ]
    }
   ],
   "source": [
    "# Extra trees\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "ec =  ExtraTreesClassifier(n_estimators=100, random_state=0)\n",
    "ec.fit(x_train, np.argmax(labels_train,axis = 1))\n",
    "print('test accuracy: ',ec.score(x_test,np.argmax(labels_test,axis = 1)))\n",
    "print('aside accuracy: ',ec.score(x_aside,np.argmax(labels_aside,axis = 1)))\n",
    "print('PGD aside accuracy: ',ec.score(x_pgd, np.argmax(labels_aside,axis = 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1293543,
     "status": "ok",
     "timestamp": 1638344324750,
     "user": {
      "displayName": "Silence Ma",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "01344304277965432029"
     },
     "user_tz": 480
    },
    "id": "7R3SnIGoxJrH",
    "outputId": "f05382f6-bdb0-4d65-e1ec-af12faeb788c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy:  0.6287878787878788\n",
      "aside accuracy:  0.6166666666666667\n",
      "PGD aside accuracy:  0.575\n"
     ]
    }
   ],
   "source": [
    "# Gradient boosting\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "gb = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=1, random_state=0)\n",
    "gb.fit(x_train, np.argmax(labels_train,axis = 1))\n",
    "print('test accuracy: ',gb.score(x_test,np.argmax(labels_test,axis = 1)))\n",
    "print('aside accuracy: ',gb.score(x_aside,np.argmax(labels_aside,axis = 1)))\n",
    "print('PGD aside accuracy: ',gb.score(x_pgd, np.argmax(labels_aside,axis = 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 28325,
     "status": "ok",
     "timestamp": 1638344353070,
     "user": {
      "displayName": "Silence Ma",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "01344304277965432029"
     },
     "user_tz": 480
    },
    "id": "EnUy48OsoBCz",
    "outputId": "c917a53e-17b2-4154-a956-65770a0de9f2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/keras/engine/training_v1.py:2057: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates = self.state_updates\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PGD MobileNet aside test loss, test acc: [5.036377607782682, 0.5083333]\n"
     ]
    }
   ],
   "source": [
    "# load MobileNet and build model\n",
    "SAVE_ROOT_DIR = 'drive/My Drive/CS504(AML)/Course Project/'\n",
    "model_MobileNet = keras.models.load_model(SAVE_ROOT_DIR + 'BUSI_dataset_MobileNet.h5')\n",
    "model_MobileNet.build((224,224,3))\n",
    "# Adam optimizer\n",
    "optimizer = keras.optimizers.Adam(learning_rate=0.0001)\n",
    "# compile the keras model\n",
    "model_MobileNet.compile(loss = 'categorical_crossentropy', optimizer = optimizer, metrics = ['accuracy'])\n",
    "# evaluate the keras model with aside images\n",
    "results = model_MobileNet.evaluate(x_test_adv, labels_aside)\n",
    "print(\"PGD MobileNet aside test loss, test acc:\", results)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyO8YXc9UM/kW2u4LOHRcx99",
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "BUSI_resnet50_PGD.ipynb",
   "provenance": [
    {
     "file_id": "1Hecpe9FBPCSVVJ3HE6prAXWy5-Xv4DmW",
     "timestamp": 1630906214757
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
